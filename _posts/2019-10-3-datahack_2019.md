---
title: "Datahack 2019: 2nd place on the Armis challenge and fun with anomaly detection"
date: 2019-10-3
share: true
header:
  image: "assets/images/datahack2019/header_img.png"
  teaser: "assets/images/datahack2019/header_img.png"
---

## My first hackathon
A few weeks ago I had a chance to participate in my first data science hackathon - [Datahack 2019](https://www.datahack.org.il/), which took place in Jerusalem. I joined a good friend and previous graduate of my lab as the final member of a team incidentally composed almost entirely of neuro/biology PhD graduates, and we signed up for the ["devices gone rogue" anomaly detection challenge](https://www.datahack.org.il/challenge/armis-devices-gone-rogue) presented by [Armis](https://www.armis.com/).

With two free days before the event that I could spend studying ahead, I came very prepared having read anything that I could find about common approaches to anomaly detection problems and with a few ideas of my own. The event itself was a great deal of fun, I got to know some wonderful teammates and we eventually ended up on the 2nd place for this challenge.

## The devices-gone-rogue challenge

Armis's product is an IoT security platform, that identifies threats coming from any type of device in an organization's network (phones, printers, smart televisions, vehicles, medical instruments, etc.). Appropriately, the [challenge](https://github.com/armis-security/DataHack2019) presented in the Datahack was to determine, based on a large database of network traffic events, devices with suspicious (i.e., anomalous) behavior.

![sessions image](../assets/images/datahack2019/sessions.png "Taken from https://github.com/armis-security/DataHack2019")

Our team's solution, along with explanation and even a PPT presentation, is available on github: [https://github.com/YG15/DataHack2019] (credit due to my team members [Tali Shrem](https://www.linkedin.com/in/talia-shrem-84a404a9/), [Guy Sheffer](https://www.linkedin.com/in/guy-sheffer-79761634/), [Yonathan Guttel](https://www.linkedin.com/in/yonathan-guttel/), [Inbal Meir](https://www.linkedin.com/in/inbal-meir-177b5516/) and myself).

By the way, the 1st place solution can be found [here](https://github.com/dmarcous/Self-Supervised-Network-Anomaly-Detection?fbclid=IwAR02I0JsfydDS1ud7uHezbw9CbwZWBNROpRTlmY54os0bEmDtV0daw2dfa0). Achieving an area-under-the-ROC-curve of ~0.9 compared to our 0.87, it is a great deal more complex and incorporates domain-expertise-based feature engineering and model ensembling. Worth a look.

## Our solution
Fairly quickly into the work we decided on a simple pipeline comprising of data exploration, feature engineering, and modeling with isolation forest (optionally ensembling other models later). By dividing ourselves among the different tasks, it was easy to start with some initial features and a simple model to establish the workflow, and then gradually add to it as each update is carried downstream along the already established pipeline.

### exploring the data
The data included traffic from five consecutive days and four different networks. Our first priority was to understand how these time and space properties impact the data: is there a daily cyclic traffic pattern for some device types? should similar devices on different network be modeled separately or should their data be pooled together? The former question is particularly relevant for anomaly detection, since if different times of day correspond e.g. to different traffic volume baselines, this variance can be regressed out so that it would not mask local rather than global outliers.  

Overall, traffic features tended to stay uniform across the day, with some notable exceptions. For example, packet loss for mobile phones was higher during peak traffic hours than during the night (background hex color corresponds to how many sessions there were for each hour x loss combination, line to mean packet loss values for each hour, error bars to standard error across days):

![mobile phone packet loss over time](../assets/images/datahack2019/mobile_packet_loss.png)

No differences were found between days or networks; we therefore handled this variance by subtracting from each traffic parameter its hour-specific mean, pooling data from all days and networks.

### Feature engineering and selection

Each 
